{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13e63b89-ece2-4799-b0a9-a3402ba95917",
   "metadata": {
    "collapsed": false,
    "name": "cell0"
   },
   "source": [
    "Basket Analysis\n",
    "\n",
    "Neo4j GDS on Snowflake v0.3.13\n",
    "\n",
    "Last Updated: 7 May 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70fdb6f-4ec9-4e88-8c66-0ab4be324f15",
   "metadata": {
    "collapsed": false,
    "name": "cell1"
   },
   "source": [
    "## Setting Up\n",
    "Before we run our algorithms, we need to set the proper permissions. But before we get started granting different roles, we need to ensure that you are using `accountadmin` to grant and create roles. Lets do that now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b304f52-660a-4162-ba9c-fb3ad2835367",
   "metadata": {
    "language": "sql",
    "name": "cell2"
   },
   "outputs": [],
   "source": [
    "-- you must be accountadmin to create role and grant permissions\n",
    "USE ROLE accountadmin;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69ca343-91a9-4867-8bec-aab3e902fa29",
   "metadata": {
    "collapsed": false,
    "name": "cell3"
   },
   "source": [
    "Create a database which we will use to prepare data for Graph Analytics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afaf9a4-114b-4a93-938e-232e4247d23d",
   "metadata": {
    "language": "sql",
    "name": "cell4"
   },
   "outputs": [],
   "source": [
    "-- Create a database which we will use to prepare data for Graph Analytics.\n",
    "CREATE DATABASE IF NOT EXISTS product_recommendation;\n",
    "CREATE SCHEMA IF NOT EXISTS product_recommendation.public;\n",
    "USE SCHEMA product_recommendation.public;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54d1480-505b-45e6-9546-fd08c964a63d",
   "metadata": {
    "collapsed": false,
    "name": "cell5"
   },
   "source": [
    "Next let's set up the necessary roles, permissions, and resource access to enable Graph Analytics to operate on data within the neo4j_imdb.public schema. It creates a consumer role (gds_role) for users and administrators, grants the GDS application access to read from and write to tables and views, and ensures that future tables are accessible.\n",
    "\n",
    "It also provides the application with access to the required compute pool and warehouse resources needed to run graph algorithms at scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db14318-a480-4687-8057-d69a4169d085",
   "metadata": {
    "language": "sql",
    "name": "cell6"
   },
   "outputs": [],
   "source": [
    "USE SCHEMA product_recommendation.public;\n",
    "\n",
    "-- Create a consumer role for users and admins of the GDS application\n",
    "CREATE ROLE IF NOT EXISTS gds_user_role;\n",
    "CREATE ROLE IF NOT EXISTS gds_admin_role;\n",
    "GRANT APPLICATION ROLE neo4j_graph_analytics.app_user TO ROLE gds_user_role;\n",
    "GRANT APPLICATION ROLE neo4j_graph_analytics.app_admin TO ROLE gds_admin_role;\n",
    "\n",
    "CREATE DATABASE ROLE IF NOT EXISTS gds_db_role;\n",
    "GRANT DATABASE ROLE gds_db_role TO ROLE gds_user_role;\n",
    "GRANT DATABASE ROLE gds_db_role TO APPLICATION neo4j_graph_analytics;\n",
    "\n",
    "-- Grant access to consumer data\n",
    "GRANT USAGE ON DATABASE product_recommendation TO ROLE gds_user_role;\n",
    "GRANT USAGE ON SCHEMA product_recommendation.public TO ROLE gds_user_role;\n",
    "\n",
    "-- Required to read tabular data into a graph\n",
    "GRANT SELECT ON ALL TABLES IN DATABASE product_recommendation TO DATABASE ROLE gds_db_role;\n",
    "\n",
    "-- Ensure the consumer role has access to created tables/views\n",
    "GRANT ALL PRIVILEGES ON FUTURE TABLES IN SCHEMA product_recommendation.product_recommendation TO DATABASE ROLE gds_db_role;\n",
    "GRANT ALL PRIVILEGES ON ALL TABLES IN SCHEMA product_recommendation.product_recommendation TO DATABASE ROLE gds_db_role;\n",
    "GRANT CREATE TABLE ON SCHEMA product_recommendation.product_recommendation TO DATABASE ROLE gds_db_role;\n",
    "GRANT CREATE VIEW ON SCHEMA product_recommendation.product_recommendation TO DATABASE ROLE gds_db_role;\n",
    "GRANT ALL PRIVILEGES ON FUTURE VIEWS IN SCHEMA product_recommendation.product_recommendation TO DATABASE ROLE gds_db_role;\n",
    "GRANT ALL PRIVILEGES ON ALL VIEWS IN SCHEMA product_recommendation.product_recommendation TO DATABASE ROLE gds_db_role;\n",
    "\n",
    "-- Compute and warehouse access\n",
    "GRANT USAGE ON WAREHOUSE GDSONSNOWFLAKE TO APPLICATION neo4j_graph_analytics;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0767b38-7c8c-4445-a0d2-6213755a87d2",
   "metadata": {
    "language": "sql",
    "name": "cell7"
   },
   "outputs": [],
   "source": [
    "USE ROLE gds_user_role;\n",
    "\n",
    "-- The application reads data from tables that represent nodes and relationships.\n",
    "-- Nodes are usually represented by entity tables, like persons or products.\n",
    "-- Relationships are foreign keys between entity tables (1:1, 1:n) or via mapping tables (n:m).\n",
    "-- In addition, the application expects certain naming conventions on column names.\n",
    "-- If the data is not yet in the right format, we can use views to get there.\n",
    "\n",
    "-- For our analysis, we will use two different types of nodes: parts and orders.\n",
    "-- We want to find similar parts by looking at the orders in which they appeared.\n",
    "-- The relationships will be the line items linking a part to an order.\n",
    "-- The result will be a new table containing pairs of parts including their similarity score.\n",
    "\n",
    "-- We start by creating two views to represent our node tables.\n",
    "-- The application requires a node table to contain a 'nodeId' column.\n",
    "-- Since we do not need any node properties, this will be the only column we project.\n",
    "-- Note that the `nodeId` column is used to uniquely identify a node in the table.\n",
    "-- The uniqueness is usually achieved by using the primary key in that table, here 'p_partkey'.\n",
    "\n",
    "CREATE OR REPLACE VIEW parts AS\n",
    "SELECT p_partkey AS nodeId FROM snowflake_sample_data.tpch_sf1.part;\n",
    "\n",
    "-- We do the same for the orders by projecting the `o_orderkey` to 'nodeId'.\n",
    "CREATE OR REPLACE VIEW orders AS\n",
    "SELECT o_orderkey AS nodeId FROM snowflake_sample_data.tpch_sf1.orders;\n",
    "\n",
    "-- The line items represent the relationship between parts and orders.\n",
    "-- The application requires a `sourceNodeId` and a `targetNodeId` column to identify.\n",
    "-- Here, a part is the source of a relationship and an order is the target.\n",
    "CREATE OR REPLACE VIEW part_in_order AS\n",
    "SELECT\n",
    "    l_partkey AS sourceNodeId,\n",
    "    l_orderkey AS targetNodeId\n",
    "FROM snowflake_sample_data.tpch_sf1.lineitem;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6618a464-fc88-4e5e-8a6b-4a8fc0c5cb81",
   "metadata": {
    "language": "sql",
    "name": "cell10"
   },
   "outputs": [],
   "source": [
    "\n",
    "CREATE OR REPLACE TABLE TPCH_EXAMPLE.GDS.PARTS(\n",
    "\tP_PARTKEY NUMBER(38,0),\n",
    "\tP_NAME VARCHAR(55),\n",
    "\tP_MFGR VARCHAR(25),\n",
    "\tP_BRAND VARCHAR(10),\n",
    "\tP_TYPE VARCHAR(25),\n",
    "\tP_SIZE NUMBER(38,0),\n",
    "\tP_CONTAINER VARCHAR(10),\n",
    "\tP_RETAILPRICE NUMBER(12,2),\n",
    "\tP_COMMENT VARCHAR(23)\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10ecf03-fbef-4854-9fee-887a45487f1c",
   "metadata": {
    "collapsed": false,
    "name": "cell11"
   },
   "source": [
    "[Stages](https://docs.snowflake.com/en/user-guide/data-load-local-file-system-create-stage.html) in snowflake are places that you can land your data before it is uploaded to a Snowflake table. You might have a batch of CSV files living on a disk driver somewhere, and, in order to start querying the data via a table, the data must be landed within the Snowflake environment for a data upload to be possible.\n",
    "\n",
    "In the exercise, we will be working with structured, comma-delimited data that has already been staged in a public, external AWS bucket. Before we can use this data, we first need to create a `Stage` that specifies the location of our external bucket.\n",
    "\n",
    "Letâ€™s create the \"stage\" object. \"Stages\" are typically created by Storage Administrators, but for the purposes of this lab, YOU will be creating this object. Again, lets click back on \"Worksheets\" tab  on the left hand side and excute the next following lines of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e9bbe2-cf86-4db5-bbc1-e18cfe2fb2db",
   "metadata": {
    "language": "sql",
    "name": "cell12"
   },
   "outputs": [],
   "source": [
    "-- you must be accountadmin to create role and grant permissions\n",
    "USE ROLE accountadmin;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7b2c44-57db-49ed-82a1-d6bd3078dec3",
   "metadata": {
    "language": "sql",
    "name": "cell13"
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE STAGE sf_neo4j_data_stage\n",
    "  URL = 's3://neo4j-snowflake-data/tpc-h/';"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb88060d-fc31-4c50-a50a-c5ecb7d818cc",
   "metadata": {
    "collapsed": false,
    "name": "cell14"
   },
   "source": [
    "We also can take a look at the contents of the `sf_neo4j_data_stage` by executing the follow:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafadc16-908c-49fc-9494-308bbd1224b4",
   "metadata": {
    "language": "sql",
    "name": "cell15"
   },
   "outputs": [],
   "source": [
    "ls @sf_neo4j_data_stage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cefd816-ddd5-4c9a-a16e-7f0555fa10e8",
   "metadata": {
    "collapsed": false,
    "name": "cell16"
   },
   "source": [
    "[File Formats](https://docs.snowflake.com/en/sql-reference/sql/create-file-format.html) tell Snowflake the structure of the data coming in. The last thing that we need to do before we can load the data into our Snowflake tables is: we have to create a `File Format` that matches the data structure of the local files we want to upload. As smart as Snowflake is, its not THAT smart.\n",
    "\n",
    "For our example, our data has header columns in the CSV, so we want to skip those. A comma delimiter is the default way to delimit CSV files (hence the name), but sometimes you can choose another character. We need to give Snowflake all the details on how we have organized our data in the files we want to load in. Please execute the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec60978-0bc0-4987-9f89-9e03ab26cd50",
   "metadata": {
    "language": "sql",
    "name": "cell17"
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE FILE FORMAT tpch_ff\n",
    "  TYPE = 'CSV'\n",
    "  COMPRESSION = 'AUTO'\n",
    "  FIELD_DELIMITER = ','\n",
    "  RECORD_DELIMITER = '\\n'\n",
    "  SKIP_HEADER = 1\n",
    "  FIELD_OPTIONALLY_ENCLOSED_BY = 'NONE'\n",
    "  TRIM_SPACE = FALSE\n",
    "  ERROR_ON_COLUMN_COUNT_MISMATCH = TRUE\n",
    "  ESCAPE = 'NONE'\n",
    "  ESCAPE_UNENCLOSED_FIELD = '\\134'\n",
    "  DATE_FORMAT = 'AUTO'\n",
    "  TIMESTAMP_FORMAT = 'AUTO'\n",
    "  NULL_IF = ('\\\\N');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3479fe1b-2043-4200-ab05-a63dad23ccf7",
   "metadata": {
    "language": "sql",
    "name": "cell18"
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE FILE FORMAT tpch_tab_ff\n",
    "  TYPE = 'CSV'\n",
    "  COMPRESSION = 'AUTO'\n",
    "  FIELD_DELIMITER = '\\t'\n",
    "  RECORD_DELIMITER = '\\n'\n",
    "  SKIP_HEADER = 1\n",
    "  FIELD_OPTIONALLY_ENCLOSED_BY = 'NONE'\n",
    "  TRIM_SPACE = FALSE\n",
    "  ERROR_ON_COLUMN_COUNT_MISMATCH = TRUE\n",
    "  ESCAPE = 'NONE'\n",
    "  ESCAPE_UNENCLOSED_FIELD = '\\134'\n",
    "  DATE_FORMAT = 'AUTO'\n",
    "  TIMESTAMP_FORMAT = 'AUTO'\n",
    "  NULL_IF = ('\\\\N');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24078e9e-2758-40e0-bf25-3b4d11841e1f",
   "metadata": {
    "collapsed": false,
    "name": "cell19"
   },
   "source": [
    "In this section, we will use a virtual [warehouse](https://docs.snowflake.com/en/user-guide/warehouses-overview.html) and the [COPY command](https://docs.snowflake.com/en/sql-reference/sql/copy-into-table.html) to initiate bulk loading of the CSV file sitting in our AWS external stage, moving it into the Snowflake table we just created.\n",
    "\n",
    "We can run a COPY command to load the data into the `tpch_example` database we created earlier. Go ahead and execute the next set of statements in the worksheet to load the staged data into the tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee718f82-b9b0-40bb-bdff-cb0e954cdd4c",
   "metadata": {
    "language": "sql",
    "name": "cell20"
   },
   "outputs": [],
   "source": [
    "USE ROLE gds_user_role;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbde6198-fd80-43b9-bde7-b4c1d6c59c0a",
   "metadata": {
    "language": "sql",
    "name": "cell21"
   },
   "outputs": [],
   "source": [
    "COPY INTO PARTS FROM @sf_neo4j_data_stage/TPCH_Part.tsv\n",
    "  FILE_FORMAT = (FORMAT_NAME = tpch_tab_ff);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce779dc-8d36-445e-9b0b-4414d5894073",
   "metadata": {
    "language": "sql",
    "name": "cell22"
   },
   "outputs": [],
   "source": [
    "COPY INTO ORDERS FROM @sf_neo4j_data_stage/TPCH_Orders.tsv\n",
    "  FILE_FORMAT = (FORMAT_NAME = tpch_tab_ff);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69308377-e10a-4c42-8878-75ed284f2e19",
   "metadata": {
    "language": "sql",
    "name": "cell23"
   },
   "outputs": [],
   "source": [
    "COPY INTO LINEITEM FROM @sf_neo4j_data_stage/TPCH_LineItems.tsv\n",
    "  FILE_FORMAT = (FORMAT_NAME = tpch_tab_ff);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24d8882-f98d-4364-a131-2c57d4a7c2db",
   "metadata": {
    "collapsed": false,
    "name": "cell24"
   },
   "source": [
    "## Creating the necessary views\n",
    "\n",
    "For our analysis, we will use two different types of nodes: parts and orders.\n",
    "We want to find similar parts by looking at the orders in which they appeared.\n",
    "The relationships will be the line items linking a part to an order.\n",
    "The result will be a new table containing pairs of parts including their similarity score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2596998f-2daa-45b9-b909-b67838c46dd3",
   "metadata": {
    "language": "sql",
    "name": "cell25"
   },
   "outputs": [],
   "source": [
    "-- Since we do not need any node properties, this will be the only column we project.\n",
    "-- Note, that the `nodeId` column is used to uniquely identify a node in the table.\n",
    "-- The uniqueness is usually achieved by using the primary key in that table, here 'p_partkey'.\n",
    "CREATE OR REPLACE VIEW TPCH_EXAMPLE.GDS.PART_VW (nodeId) AS\n",
    "SELECT p.P_PARTKEY AS nodeId FROM TPCH_EXAMPLE.GDS.PARTS p;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a7b91c-ea8d-4a40-9f30-c92acb5c6d10",
   "metadata": {
    "language": "sql",
    "name": "cell26"
   },
   "outputs": [],
   "source": [
    "-- We do the same for the orders by projecting the `o_orderkey` to 'nodeId'.\n",
    "-- Since order is a reserved word in SQL, we utilize a quoted identifier.\n",
    "CREATE OR REPLACE VIEW TPCH_EXAMPLE.GDS.ORDER_VW (nodeId) AS\n",
    "SELECT o.O_ORDERKEY AS nodeId FROM TPCH_EXAMPLE.GDS.ORDERS o;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85846f4c-90c7-4b47-8c97-aed58fc7de3f",
   "metadata": {
    "language": "sql",
    "name": "cell27"
   },
   "outputs": [],
   "source": [
    "-- The line items represent the relationship between parts and orders. \n",
    "-- GDS requires a sourceNodeId and a targetNodeId column to identify.\n",
    "-- Here, a part is the source of a relationship and an order is the target. \n",
    "\n",
    "CREATE OR REPLACE VIEW TPCH_EXAMPLE.GDS.PART_IN_ORDER(sourceNodeId, targetNodeId) \n",
    "AS \n",
    "SELECT l.l_partkey AS sourceNodeId, l.l_orderkey AS targetNodeId \n",
    "FROM TPCH_EXAMPLE.GDS.LINEITEM l;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eae9c3b-660c-4be2-b367-837c784bdf60",
   "metadata": {
    "collapsed": false,
    "name": "cell28"
   },
   "source": [
    "Next, we want to consider the warehouse that the GDS application will use to execute queries.\n",
    "For this example a MEDIUM size warehouse, so we configure the application's warehouse accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0145ecfe-f6f1-4191-b264-e35477b7181a",
   "metadata": {
    "language": "sql",
    "name": "cell29"
   },
   "outputs": [],
   "source": [
    "ALTER WAREHOUSE neo4j_graph_analytics_app_warehouse SET WAREHOUSE_SIZE='MEDIUM';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e9f3d7-8025-45f0-b6e6-9b759923c75b",
   "metadata": {
    "language": "sql",
    "name": "cell30"
   },
   "outputs": [],
   "source": [
    "SELECT TO_CHAR(SOURCENODEID), TO_CHAR(TARGETNODEID) FROM TPCH_EXAMPLE.GDS.PART_IN_ORDER LIMIT 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59080094-4799-4e89-9a0d-2c4196f3c8e9",
   "metadata": {
    "collapsed": false,
    "name": "cell31"
   },
   "source": [
    "Once the session is started, we can project our node and relationship views into a GDS in-memory graph. The graph will be identified by the name \"parts_in_orders\".\n",
    "\n",
    "* The mandatory parameters are the node tables and the relationship tables.\n",
    "* A node table mapping points from a table/view to a node label that is used in the GDS graph.\n",
    "* The name of node label is based on the table/view name used in the projection, and case is preserved.\n",
    "For example, the rows of 'tpch_example.gds.Part' will be nodes labeled as 'Part'.\n",
    "* Relationship tables need a bit more configuration.\n",
    "We need to specify source and target tables.\n",
    "* The relationships are represented as typed relationships is the GDS graph, where similarly to nodes, the table/view name is taken as the relationship type.\n",
    "* For example, 'tpch_example.gds.part_in_order' below gives rise to the relationship 'part_in_order' in the GDS graph.\n",
    "* We also specify the optional read concurrency to optimize building the graph projection.\n",
    "* The concurrency can be set to the number of cores available on the compute pool node."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786748d8-9d02-4076-8a07-65afdd67e757",
   "metadata": {
    "collapsed": false,
    "name": "cell32"
   },
   "source": [
    "The graph we project is a so-called bipartite graph, as it contains two types of nodes and all relationships point from one type to the other.\n",
    "The node similarity algorithm looks at all pairs of nodes of the first type and calculates the similarity for each pair based on common relationships.\n",
    "In our case, the algorithm will calculate the similarity between two parts based on the orders in which they appear.\n",
    "The algorithm produces new relationships between parts, the relationship property is the similarity score.\n",
    "For further information on the node similarity algorithm, please refer to the [GDS documentation](https://neo4j.com/docs/graph-data-science/current/algorithms/node-similarity/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a441d0d6-0a22-4fcb-b82d-00a0f83d3990",
   "metadata": {
    "collapsed": false,
    "name": "cell33"
   },
   "source": [
    "Once the algorithm has finished, we can write the results back to Snowflake tables for further analysis.\n",
    "We want to write back the similarity relationships between parts. \n",
    "The specified table will contain the original source and target node ids and the similarity score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2247dfa5-abcf-482b-91b2-9ce38840a3f6",
   "metadata": {
    "language": "sql",
    "name": "cell34"
   },
   "outputs": [],
   "source": [
    "CALL neo4j_graph_analytics.graph.node_similarity('CPU_X64_L', {\n",
    "  'project': {\n",
    "    'defaultTablePrefix': 'tpch_example.gds',\n",
    "    'nodeTables': ['Part_VW','Order_VW'], \n",
    "    'relationshipTables': {\n",
    "      'part_in_order': {\n",
    "        'sourceTable': 'Part_VW',\n",
    "        'targetTable': 'Order_VW'\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "  'compute': { 'topK': 2,\n",
    "                'concurrency': 28 },\n",
    "  'write': [\n",
    "    {\n",
    "    'sourceLabel':          'Part_VW',\n",
    "    'targetLabel':          'Part_VW',\n",
    "    'relationshipType':     'SIMILAR_TO',\n",
    "    'relationshipProperty': 'similarity',\n",
    "    'outputTable':          'tpch_example.gds.part_similar_to_part'\n",
    "    }\n",
    "  ]\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87b0916-9cdd-4377-ae8f-a07c838073e8",
   "metadata": {
    "collapsed": false,
    "name": "cell35"
   },
   "source": [
    "After writing the table, we need to ensure that our current role is allowed to read it.\n",
    "Alternatively, we can also grant access to all future tables created by the application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb24431-c49e-47b8-bbfa-62dfa46c1be1",
   "metadata": {
    "language": "sql",
    "name": "cell36"
   },
   "outputs": [],
   "source": [
    "GRANT SELECT ON TPCH_EXAMPLE.GDS.PART_SIMILAR_TO_PART TO ROLE gds_user_role;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b6d40b-67c2-4879-bffe-0c3bcdca5195",
   "metadata": {
    "collapsed": false,
    "name": "cell37"
   },
   "source": [
    "Since the results are now stored in Snowflake, we can query them and join them with our original data.\n",
    "For example, we can find the names of the most similar parts based on the similarity score.\n",
    "Simply speaking, this could be used as a recommendation system for parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f2ca75-2d8b-4971-9bb5-a3be5c034555",
   "metadata": {
    "language": "sql",
    "name": "cell38"
   },
   "outputs": [],
   "source": [
    "SELECT DISTINCT p_source.p_name, p_target.p_name, sim.similarity\n",
    "FROM TPCH_EXAMPLE.GDS.PARTS p_source\n",
    "    JOIN TPCH_EXAMPLE.GDS.PART_SIMILAR_TO_PART sim\n",
    "        ON p_source.p_partkey = sim.sourcenodeid\n",
    "    JOIN TPCH_EXAMPLE.GDS.PARTS p_target\n",
    "        ON p_target.p_partkey = sim.targetnodeid\n",
    "ORDER BY sim.similarity DESC LIMIT 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea473f6-1b3a-4f52-b144-743bcfbdf2bb",
   "metadata": {
    "language": "sql",
    "name": "cell39"
   },
   "outputs": [],
   "source": [
    "USE ROLE ACCOUNTADMIN;\n",
    "GRANT OWNERSHIP ON TABLE TPCH_EXAMPLE.GDS.part_similar_to_part TO ROLE gds_user_role REVOKE CURRENT GRANTS;\n",
    "USE ROLE gds_user_role;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2043e223-11b6-40f3-998f-1172fd33b516",
   "metadata": {
    "collapsed": false,
    "name": "cell40"
   },
   "source": [
    "The GDS service is a long-running service and should be stopped when not in use.\n",
    "Once we completed our analysis, we can stop the session, which suspends the container service.\n",
    "We can restart the session at any time to continue our analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "authorEmail": "david.fauth@neo4j.com",
   "authorId": "8305788275502",
   "authorName": "DFAUTH",
   "lastEditTime": 1746627765792,
   "notebookId": "nujgz4gu27x47bc44jgq",
   "sessionId": "0a9df962-d9a3-4450-a3b4-feb32afbe1b8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
